{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = 10\n",
    "IMAGE_SIZE = 28\n",
    "\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "TRAINING_ITERATIONS = 20000\n",
    "BATCH = 50\n",
    "KERNEL_SIZE = 5\n",
    "DEPTH = 32\n",
    "DENSE_HIDDEN_LAYERS = 1024\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "train_df = data.iloc[:, 1:].values\n",
    "train_df = train_df.astype(np.float)\n",
    "\n",
    "train_df = np.multiply(train_df, 1.0 / 255.0)\n",
    "\n",
    "labels_flat = data.iloc[:, 0].values.ravel()\n",
    "\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, LABELS)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "\n",
    "validation_data = train_df[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_data = train_df[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder('float', shape=[None, IMAGE_SIZE * IMAGE_SIZE])\n",
    "y_ = tf.placeholder('float', shape=[None, LABELS])\n",
    "\n",
    "input_layer = tf.reshape(X, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=DEPTH,\n",
    "    kernel_size=[KERNEL_SIZE, KERNEL_SIZE],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=2 * DEPTH,\n",
    "    kernel_size=[KERNEL_SIZE, KERNEL_SIZE],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)  \n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "pool2_flat = tf.reshape(pool2, [-1, IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 2 *DEPTH])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=DENSE_HIDDEN_LAYERS, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense, rate=0.5)\n",
    "\n",
    "logits = tf.layers.dense(inputs=dropout, units=LABELS)\n",
    "\n",
    "y = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=y_, logits=logits)\n",
    "train_step = tf.train.AdamOptimizer(LR).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "predict = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Batches\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_data.shape[0]\n",
    "\n",
    "\n",
    "def next_batch(batch_size):\n",
    "    global train_data\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_data = train_data[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_data[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start TensorFlow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.14 | 0.18 for step 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.24 | 0.26 for step 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.34 | 0.30 for step 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.28 | 0.32 for step 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.44 | 0.42 for step 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.60 | 0.46 for step 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.54 | 0.54 for step 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.66 | 0.68 for step 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.70 | 0.68 for step 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.60 | 0.66 for step 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.76 | 0.74 for step 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.84 | 0.84 for step 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.92 | 0.88 for step 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.94 | 0.94 for step 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 0.94 for step 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 0.96 for step 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 0.96 for step 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.92 | 0.96 for step 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.94 | 0.96 for step 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 0.92 for step 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 0.96 for step 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 0.98 for step 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 0.98 for step 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 1.00 for step 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 1.00 for step 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 1.00 for step 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 1.00 for step 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.96 | 1.00 for step 900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 1.00 for step 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 0.98 | 1.00 for step 6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy | validation_accuracy = 1.00 | 1.00 for step 19999\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "display_step = 1\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "    # get new batch\n",
    "    batch_xs, batch_ys = next_batch(BATCH)        \n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i % display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch_xs, \n",
    "                                                  y_: batch_ys})       \n",
    "        if VALIDATION_SIZE:\n",
    "            validation_accuracy = accuracy.eval(feed_dict={X: validation_data[0:BATCH], \n",
    "                                                           y_: validation_labels[0:BATCH]})                                  \n",
    "            print('training_accuracy | validation_accuracy = %.2f | %.2f for step %d' % (train_accuracy, \n",
    "                                                                                         validation_accuracy,\n",
    "                                                                                         i))\n",
    "            \n",
    "        else:\n",
    "            print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        \n",
    "        # increase display_step\n",
    "        if i % (display_step*10) == 0 and i:\n",
    "            display_step *= 10\n",
    "    # train on batch\n",
    "    sess.run(train_step, feed_dict={X: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_accuracy => 0.9940\n"
     ]
    }
   ],
   "source": [
    "if VALIDATION_SIZE:\n",
    "    validation_accuracy = accuracy.eval(feed_dict={X: validation_data, \n",
    "                                                   y_: validation_labels})\n",
    "    print('validation_accuracy => %.4f' % validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv').values\n",
    "\n",
    "predictions = np.zeros(test_data.shape[0])\n",
    "for i in range(0, test_data.shape[0] // BATCH):\n",
    "    predictions[i*BATCH: (i+1)*BATCH] = predict.eval(feed_dict={X: test_data[i*BATCH: (i+1)*BATCH]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission3.csv', \n",
    "           np.c_[range(1, len(test_data) + 1), predictions], \n",
    "           delimiter=',', \n",
    "           header='ImageId,Label', \n",
    "           comments='', \n",
    "           fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
