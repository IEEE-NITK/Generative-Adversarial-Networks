{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plot\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "X_dim = 784\n",
    "c_dim = 10\n",
    "h_dim = 1024\n",
    "d_steps = 5\n",
    "lamda_cls = 0.1\n",
    "lamda_rec = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(samples):\n",
    "    fig = plot.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plot.subplot(gs[i])\n",
    "        plot.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plot.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(X, reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        h1 = tf.layers.dense(X, 1024, tf.nn.relu, name=\"disc_common\")\n",
    "\n",
    "        out_disc = tf.layers.dense(h1, 1, tf.nn.sigmoid, name=\"disc_disc\")\n",
    "        out_class = tf.layers.dense(h1, c_dim, tf.nn.softmax, name=\"disc_class\")\n",
    "\n",
    "        return out_disc, out_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x, c, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        inp = tf.concat([x, c], axis=1)\n",
    "        h1 = tf.layers.dense(inp, 1024, tf.nn.relu, name=\"gen_h\")\n",
    "        out = tf.layers.dense(h1, 784, tf.nn.sigmoid, name=\"gen_out\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_image = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "real_labels = tf.placeholder(dtype=tf.float32, shape=[None, c_dim])\n",
    "fake_labels = tf.placeholder(dtype=tf.float32, shape=[None, c_dim])\n",
    "alpha = tf.placeholder(dtype=tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_image = generator(real_image, fake_labels, False)\n",
    "real_disc, real_class = discriminator(real_image)\n",
    "fake_disc, fake_class = discriminator(fake_image, True)\n",
    "rec_image = generator(fake_image, real_labels, True)\n",
    "interpolated = alpha * real_image + (1 - alpha) * fake_image\n",
    "int_disc, int_cls = discriminator(interpolated, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_loss_fake = tf.reduce_mean(fake_disc)\n",
    "gen_loss_rec = tf.reduce_mean(tf.abs(real_image - rec_image))\n",
    "gen_loss_class = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_class, labels=fake_labels))\n",
    "\n",
    "gen_loss = gen_loss_fake + lamda_rec * gen_loss_rec + lamda_cls * gen_loss_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_loss_real = tf.reduce_mean(real_disc)\n",
    "disc_loss_cls = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_class, labels=real_labels))\n",
    "disc_loss_fake = tf.reduce_mean(fake_disc)\n",
    "\n",
    "disc_loss = disc_loss_real + disc_loss_fake + lamda_cls * disc_loss_cls\n",
    "grads = tf.gradients(int_disc, [interpolated])\n",
    "grad_penalty = tf.reduce_mean(tf.square(tf.norm(grads[0], ord=2) - 1.0))\n",
    "\n",
    "disc_grad_penalty = 10 * grad_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_fake_label(batch_size):\n",
    "    idx = np.random.randint(0, 10)\n",
    "    c = np.zeros([batch_size, c_dim])\n",
    "    c[range(batch_size), idx] = 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alpha(batch_size):\n",
    "    return np.random.rand(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vars = tf.trainable_variables()\n",
    "generator_vars = [var for var in all_vars if var.name.startswith('gen')]\n",
    "discriminator_vars = [var for var in all_vars if var.name.startswith('disc')]\n",
    "\n",
    "d_optim = tf.train.AdamOptimizer(0.001).minimize(disc_loss, var_list=discriminator_vars)\n",
    "d_grad_pen = tf.train.AdamOptimizer(0.001).minimize(disc_grad_penalty, var_list=discriminator_vars)\n",
    "\n",
    "g_optim = tf.train.AdamOptimizer(0.001).minimize(gen_loss, var_list=generator_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0: G: 0.1722393035888672 ; D: 0.5331546664237976\n",
      "Epoch: 0, Iteration: 100: G: 0.10187432169914246 ; D: 0.06894289702177048\n",
      "Epoch: 0, Iteration: 200: G: 0.09634210914373398 ; D: 0.06784749776124954\n",
      "Epoch: 0, Iteration: 300: G: 0.08900151401758194 ; D: 0.0697457492351532\n",
      "Epoch: 0, Iteration: 400: G: 0.08864057064056396 ; D: 0.06923242658376694\n",
      "Epoch: 0, Iteration: 500: G: 0.08821352571249008 ; D: 0.06893336027860641\n",
      "Epoch: 0, Iteration: 600: G: 0.0871540755033493 ; D: 0.06766389310359955\n",
      "Epoch: 0, Iteration: 700: G: 0.07781060039997101 ; D: 0.06948808580636978\n",
      "Epoch: 0, Iteration: 800: G: 0.0864066630601883 ; D: 0.06948162615299225\n",
      "Epoch: 0, Iteration: 900: G: 0.08663106709718704 ; D: 0.06974824517965317\n",
      "Epoch: 0, Iteration: 1000: G: 0.07768114656209946 ; D: 0.06820397824048996\n",
      "Epoch: 0, Iteration: 1100: G: nan ; D: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1157125d9410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mreal_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mfake_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_fake_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             })\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moksh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moksh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moksh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moksh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moksh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for it in range(50000 // 32):\n",
    "        for i in range(d_steps):\n",
    "            x_batch, y_batch = mnist.train.next_batch(32)\n",
    "            _, d_loss = sess.run([d_optim, disc_loss], feed_dict={\n",
    "                real_image: x_batch,\n",
    "                real_labels: y_batch,\n",
    "                fake_labels: generate_fake_label(32),\n",
    "            })\n",
    "            \n",
    "            sess.run([d_grad_pen], feed_dict={\n",
    "                real_image: x_batch,\n",
    "                real_labels: y_batch,\n",
    "                fake_labels: generate_fake_label(32),\n",
    "                alpha: get_alpha(32)\n",
    "            })\n",
    "            \n",
    "        x_batch, y_batch = mnist.train.next_batch(32)\n",
    "        _, g_loss = sess.run([g_optim, gen_loss], feed_dict={\n",
    "            real_image: x_batch,\n",
    "            real_labels: y_batch,\n",
    "            fake_labels: generate_fake_label(32),\n",
    "        })\n",
    "        if it % 100 == 0:\n",
    "            print('Epoch: {}, Iteration: {}: G: {} ; D: {}'.format(epoch, it, g_loss, d_loss))\n",
    "        \n",
    "\n",
    "#             if it % 1000 == 0:\n",
    "#                 x_batch, y_batch = mnist.train.next_batch(16)\n",
    "        \n",
    "#                 c = generate_fake_label(16)\n",
    "#                 print(c[0])\n",
    "#                 samples = sess.run(fake_image, feed_dict={\n",
    "#                     real_image: x_batch,\n",
    "#                     fake_labels: c\n",
    "#                 })\n",
    "\n",
    "#                 fig = plot_images(samples)\n",
    "#                 plot.show()\n",
    "#                 plot.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
